{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVE3fXrfrQJO",
        "outputId": "98e55d50-6144-405a-d7a1-8caeb20f70a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "for i in range(torch.cuda.device_count()):\n",
        "   print(torch.cuda.get_device_properties(i).name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7J4-1vE2Pg5",
        "outputId": "1aa6b899-6b12-42c7-a613-96dba34c5ae1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tqdm\n",
        "import pickle\n",
        "\n",
        "# Load the test set\n",
        "with open(\"/content/drive/MyDrive/test_set.pkl\", \"rb\") as f:\n",
        "    testset = pickle.load(f)\n",
        "\n",
        "total_images = len(testset)\n",
        "print(\"Total number of images in the test dataset:\", total_images)\n",
        "\n",
        "batch_size = 64  # Replace XX with your batch size\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "Ac0NBGE_YzIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc48dff-38bc-496f-ca7e-9ec6c3e75869"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in the test dataset: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, upload the file or copy the file into your google drive.\n",
        "# And mount your drive. Then load the model\n",
        "\n",
        "model = torch.load('/content/drive/MyDrive/resnet.model', map_location=torch.device('cpu')) # e.g. /content/drive/MyDrive/CS255/resnet.model\n",
        "# print(model)\n",
        "\n",
        "model = model.to('cuda:0') # if GPU available\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "_ZCqOzXDvHHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ff6949-3af5-422d-c48d-9d71633df202"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (23): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (24): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (25): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (26): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (27): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (28): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (29): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (30): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (31): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (32): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (33): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (34): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (35): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_gradient_sign_method(model, input_imgs, labels, epsilon=0.16732, device='cuda:0'):\n",
        "    input_imgs = input_imgs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    input_imgs.requires_grad = True # Ensure that we're tracking gradients for input images\n",
        "    preds = model(input_imgs) # Forward pass\n",
        "    loss = F.cross_entropy(preds, labels)    # Calculate the loss\n",
        "    model.zero_grad() # Zero all existing gradients\n",
        "    loss.backward() # Backward pass (to compute gradients)\n",
        "    data_grad = input_imgs.grad.data     # Collect the gradients of the input images\n",
        "    perturbed_image = input_imgs + epsilon * data_grad.sign()\n",
        "\n",
        "    # Adding clipping to maintain the original range of the image\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "A1wB9UNJ7j7W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd(model, input_imgs, labels, epsilon=0.09, alpha=2/255, num_iter=100, device='cuda:0'):\n",
        "    input_imgs = input_imgs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    delta = torch.zeros_like(input_imgs, requires_grad=True).to(device) # Initialize delta\n",
        "    alpha_tensor = torch.tensor(alpha, device=device, dtype=input_imgs.dtype) # Convert alpha to a tensor and send it to the correct device\n",
        "\n",
        "    for t in tqdm.tqdm(range(num_iter), desc=\"PGD Progress\"):\n",
        "        outputs = model(input_imgs + delta)  # Forward pass\n",
        "        loss = F.cross_entropy(outputs, labels) # Calculate the loss\n",
        "        model.zero_grad() # Zero all existing gradients\n",
        "        loss.backward()  # Backward pass\n",
        "        delta.data = (delta + alpha_tensor * delta.grad.detach().sign()).clamp(-epsilon, epsilon) # Update delta within the constraints of epsilon and clamp\n",
        "        delta.grad.zero_() # Zero the gradients for the next iteration\n",
        "\n",
        "    adversarial_samples = input_imgs + delta.detach() # Create adversarial samples\n",
        "\n",
        "    return adversarial_samples"
      ],
      "metadata": {
        "id": "BfN4cg-RcNoC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, dataset_loader, img_func=fast_gradient_sign_method):\n",
        "    tp, tp_5, counter = 0., 0., 0.\n",
        "    for imgs, labels in tqdm.tqdm(dataset_loader, desc=\"Validating...\"):\n",
        "        imgs = imgs.to('cuda:0')\n",
        "        labels = labels.to('cuda:0')\n",
        "        if img_func is not None:\n",
        "            imgs = imgs + img_func(model, imgs, labels)\n",
        "        with torch.no_grad():\n",
        "            preds = model(imgs)\n",
        "        tp += (preds.argmax(dim=-1) == labels).sum()\n",
        "        tp_5 += (preds.topk(5, dim=-1)[1] == labels[...,None]).any(dim=-1).sum()\n",
        "        counter += preds.shape[0]\n",
        "    acc = tp.float().item()/counter\n",
        "    top5 = tp_5.float().item()/counter\n",
        "    print(f\"Top-1 error: {(100.0 * (1 - acc)):4.2f}%\")\n",
        "    print(f\"Top-5 error: {(100.0 * (1 - top5)):4.2f}%\")\n",
        "    return acc, top5"
      ],
      "metadata": {
        "id": "Cz4kiTprHQJy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doing grid Search:-\n",
        "--> I have used type of grid search to find the epsilon value that reduces the Top-5 Accuracy to be less that 85% such according to self_test function given in the Lab4_document and found that epsilon to be ``0.16732028126716614``."
      ],
      "metadata": {
        "id": "6vr7DM4E-0yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_values = torch.linspace(start=0, end=64/255, steps=10)  # Adjust the range and steps based on your needs\n",
        "top5_accuracies = []\n",
        "\n",
        "for eps in epsilon_values:\n",
        "    print(f\"Testing with epsilon: {eps}\")\n",
        "    _, top5 = eval_model(model, testloader, lambda m, i, l: fast_gradient_sign_method(m, i, l, epsilon=eps))\n",
        "    top5_accuracies.append(top5)\n",
        "    if top5 < 0.85:\n",
        "        print(f\"Top-5 accuracy below 85% achieved with epsilon: {eps}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku_ecli98kOI",
        "outputId": "2a9107a1-c0f9-4013-cfd5-c3d882bdd1b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with epsilon: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 32.00%\n",
            "Top-5 error: 5.00%\n",
            "Testing with epsilon: 0.027886711061000824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 2/2 [00:00<00:00,  8.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 45.00%\n",
            "Top-5 error: 7.00%\n",
            "Testing with epsilon: 0.05577342212200165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 2/2 [00:00<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 54.00%\n",
            "Top-5 error: 11.00%\n",
            "Testing with epsilon: 0.08366013318300247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 2/2 [00:00<00:00,  8.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 61.00%\n",
            "Top-5 error: 13.00%\n",
            "Testing with epsilon: 0.1115468442440033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 2/2 [00:00<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 71.00%\n",
            "Top-5 error: 13.00%\n",
            "Testing with epsilon: 0.13943356275558472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 2/2 [00:00<00:00,  9.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 76.00%\n",
            "Top-5 error: 13.00%\n",
            "Testing with epsilon: 0.16732028126716614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 80.00%\n",
            "Top-5 error: 18.00%\n",
            "Top-5 accuracy below 85% achieved with epsilon: 0.16732028126716614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy, top5_accuracy = eval_model(model, testloader, fast_gradient_sign_method)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Top-5 Accuracy:\", top5_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKzQRH73abcl",
        "outputId": "080c816d-f52f-4b9f-f5e9-e3ba802bbc62"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 80.00%\n",
            "Top-5 error: 18.00%\n",
            "Accuracy: 0.2\n",
            "Top-5 Accuracy: 0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy, top5_accuracy = eval_model(model, testloader, pgd)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Top-5 Accuracy:\", top5_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpzKyGGN7Ua6",
        "outputId": "9718e873-17a4-456d-957d-4d5f676bb11b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "PGD Progress:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "PGD Progress:   2%|▏         | 2/100 [00:00<00:06, 14.14it/s]\u001b[A\n",
            "PGD Progress:   4%|▍         | 4/100 [00:00<00:06, 14.23it/s]\u001b[A\n",
            "PGD Progress:   6%|▌         | 6/100 [00:00<00:07, 13.09it/s]\u001b[A\n",
            "PGD Progress:   8%|▊         | 8/100 [00:00<00:06, 13.17it/s]\u001b[A\n",
            "PGD Progress:  10%|█         | 10/100 [00:00<00:06, 13.21it/s]\u001b[A\n",
            "PGD Progress:  12%|█▏        | 12/100 [00:00<00:06, 13.21it/s]\u001b[A\n",
            "PGD Progress:  14%|█▍        | 14/100 [00:01<00:08, 10.17it/s]\u001b[A\n",
            "PGD Progress:  16%|█▌        | 16/100 [00:01<00:08, 10.17it/s]\u001b[A\n",
            "PGD Progress:  18%|█▊        | 18/100 [00:01<00:08, 10.19it/s]\u001b[A\n",
            "PGD Progress:  20%|██        | 20/100 [00:01<00:07, 10.30it/s]\u001b[A\n",
            "PGD Progress:  22%|██▏       | 22/100 [00:01<00:07, 10.52it/s]\u001b[A\n",
            "PGD Progress:  24%|██▍       | 24/100 [00:02<00:07,  9.55it/s]\u001b[A\n",
            "PGD Progress:  25%|██▌       | 25/100 [00:02<00:08,  9.13it/s]\u001b[A\n",
            "PGD Progress:  26%|██▌       | 26/100 [00:02<00:08,  8.64it/s]\u001b[A\n",
            "PGD Progress:  27%|██▋       | 27/100 [00:02<00:08,  8.61it/s]\u001b[A\n",
            "PGD Progress:  29%|██▉       | 29/100 [00:02<00:07,  9.50it/s]\u001b[A\n",
            "PGD Progress:  31%|███       | 31/100 [00:02<00:07,  9.56it/s]\u001b[A\n",
            "PGD Progress:  32%|███▏      | 32/100 [00:03<00:07,  9.33it/s]\u001b[A\n",
            "PGD Progress:  33%|███▎      | 33/100 [00:03<00:07,  9.38it/s]\u001b[A\n",
            "PGD Progress:  34%|███▍      | 34/100 [00:03<00:07,  9.39it/s]\u001b[A\n",
            "PGD Progress:  36%|███▌      | 36/100 [00:03<00:06,  9.80it/s]\u001b[A\n",
            "PGD Progress:  38%|███▊      | 38/100 [00:03<00:05, 10.34it/s]\u001b[A\n",
            "PGD Progress:  40%|████      | 40/100 [00:03<00:05, 10.46it/s]\u001b[A\n",
            "PGD Progress:  42%|████▏     | 42/100 [00:04<00:06,  8.61it/s]\u001b[A\n",
            "PGD Progress:  43%|████▎     | 43/100 [00:04<00:06,  8.80it/s]\u001b[A\n",
            "PGD Progress:  44%|████▍     | 44/100 [00:04<00:06,  8.87it/s]\u001b[A\n",
            "PGD Progress:  45%|████▌     | 45/100 [00:04<00:06,  8.72it/s]\u001b[A\n",
            "PGD Progress:  46%|████▌     | 46/100 [00:04<00:06,  8.31it/s]\u001b[A\n",
            "PGD Progress:  47%|████▋     | 47/100 [00:04<00:06,  8.38it/s]\u001b[A\n",
            "PGD Progress:  48%|████▊     | 48/100 [00:04<00:06,  7.73it/s]\u001b[A\n",
            "PGD Progress:  49%|████▉     | 49/100 [00:05<00:06,  7.80it/s]\u001b[A\n",
            "PGD Progress:  50%|█████     | 50/100 [00:05<00:06,  7.41it/s]\u001b[A\n",
            "PGD Progress:  51%|█████     | 51/100 [00:05<00:07,  6.56it/s]\u001b[A\n",
            "PGD Progress:  52%|█████▏    | 52/100 [00:05<00:08,  5.38it/s]\u001b[A\n",
            "PGD Progress:  53%|█████▎    | 53/100 [00:05<00:09,  5.15it/s]\u001b[A\n",
            "PGD Progress:  54%|█████▍    | 54/100 [00:05<00:07,  5.82it/s]\u001b[A\n",
            "PGD Progress:  55%|█████▌    | 55/100 [00:06<00:06,  6.49it/s]\u001b[A\n",
            "PGD Progress:  56%|█████▌    | 56/100 [00:06<00:06,  6.79it/s]\u001b[A\n",
            "PGD Progress:  57%|█████▋    | 57/100 [00:06<00:05,  7.25it/s]\u001b[A\n",
            "PGD Progress:  58%|█████▊    | 58/100 [00:06<00:05,  7.61it/s]\u001b[A\n",
            "PGD Progress:  59%|█████▉    | 59/100 [00:06<00:05,  7.65it/s]\u001b[A\n",
            "PGD Progress:  60%|██████    | 60/100 [00:06<00:05,  7.79it/s]\u001b[A\n",
            "PGD Progress:  61%|██████    | 61/100 [00:06<00:04,  8.32it/s]\u001b[A\n",
            "PGD Progress:  62%|██████▏   | 62/100 [00:07<00:05,  6.46it/s]\u001b[A\n",
            "PGD Progress:  63%|██████▎   | 63/100 [00:07<00:06,  5.90it/s]\u001b[A\n",
            "PGD Progress:  64%|██████▍   | 64/100 [00:07<00:07,  5.02it/s]\u001b[A\n",
            "PGD Progress:  65%|██████▌   | 65/100 [00:07<00:07,  4.65it/s]\u001b[A\n",
            "PGD Progress:  66%|██████▌   | 66/100 [00:08<00:07,  4.41it/s]\u001b[A\n",
            "PGD Progress:  67%|██████▋   | 67/100 [00:08<00:07,  4.23it/s]\u001b[A\n",
            "PGD Progress:  68%|██████▊   | 68/100 [00:08<00:07,  4.38it/s]\u001b[A\n",
            "PGD Progress:  69%|██████▉   | 69/100 [00:08<00:06,  4.75it/s]\u001b[A\n",
            "PGD Progress:  70%|███████   | 70/100 [00:08<00:05,  5.02it/s]\u001b[A\n",
            "PGD Progress:  71%|███████   | 71/100 [00:08<00:05,  5.47it/s]\u001b[A\n",
            "PGD Progress:  72%|███████▏  | 72/100 [00:09<00:05,  5.56it/s]\u001b[A\n",
            "PGD Progress:  73%|███████▎  | 73/100 [00:09<00:04,  5.85it/s]\u001b[A\n",
            "PGD Progress:  75%|███████▌  | 75/100 [00:09<00:03,  7.72it/s]\u001b[A\n",
            "PGD Progress:  77%|███████▋  | 77/100 [00:09<00:02,  9.06it/s]\u001b[A\n",
            "PGD Progress:  79%|███████▉  | 79/100 [00:09<00:02, 10.04it/s]\u001b[A\n",
            "PGD Progress:  81%|████████  | 81/100 [00:09<00:01, 10.85it/s]\u001b[A\n",
            "PGD Progress:  83%|████████▎ | 83/100 [00:10<00:01, 11.40it/s]\u001b[A\n",
            "PGD Progress:  85%|████████▌ | 85/100 [00:10<00:01, 11.96it/s]\u001b[A\n",
            "PGD Progress:  87%|████████▋ | 87/100 [00:10<00:01, 12.48it/s]\u001b[A\n",
            "PGD Progress:  89%|████████▉ | 89/100 [00:10<00:00, 12.70it/s]\u001b[A\n",
            "PGD Progress:  91%|█████████ | 91/100 [00:10<00:00, 12.77it/s]\u001b[A\n",
            "PGD Progress:  93%|█████████▎| 93/100 [00:10<00:00, 12.80it/s]\u001b[A\n",
            "PGD Progress:  95%|█████████▌| 95/100 [00:11<00:00, 12.99it/s]\u001b[A\n",
            "PGD Progress:  97%|█████████▋| 97/100 [00:11<00:00, 11.88it/s]\u001b[A\n",
            "PGD Progress: 100%|██████████| 100/100 [00:11<00:00,  8.70it/s]\n",
            "Validating...:  50%|█████     | 1/2 [00:11<00:11, 11.53s/it]\n",
            "PGD Progress:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "PGD Progress:   2%|▏         | 2/100 [00:00<00:06, 14.54it/s]\u001b[A\n",
            "PGD Progress:   4%|▍         | 4/100 [00:00<00:07, 12.34it/s]\u001b[A\n",
            "PGD Progress:   6%|▌         | 6/100 [00:00<00:08, 11.70it/s]\u001b[A\n",
            "PGD Progress:   8%|▊         | 8/100 [00:00<00:07, 12.17it/s]\u001b[A\n",
            "PGD Progress:  10%|█         | 10/100 [00:00<00:08, 10.29it/s]\u001b[A\n",
            "PGD Progress:  12%|█▏        | 12/100 [00:01<00:07, 11.27it/s]\u001b[A\n",
            "PGD Progress:  14%|█▍        | 14/100 [00:01<00:07, 11.95it/s]\u001b[A\n",
            "PGD Progress:  16%|█▌        | 16/100 [00:01<00:06, 12.24it/s]\u001b[A\n",
            "PGD Progress:  18%|█▊        | 18/100 [00:01<00:06, 12.18it/s]\u001b[A\n",
            "PGD Progress:  20%|██        | 20/100 [00:01<00:06, 11.94it/s]\u001b[A\n",
            "PGD Progress:  22%|██▏       | 22/100 [00:01<00:06, 12.25it/s]\u001b[A\n",
            "PGD Progress:  24%|██▍       | 24/100 [00:02<00:06, 12.45it/s]\u001b[A\n",
            "PGD Progress:  26%|██▌       | 26/100 [00:02<00:05, 12.69it/s]\u001b[A\n",
            "PGD Progress:  28%|██▊       | 28/100 [00:02<00:05, 12.66it/s]\u001b[A\n",
            "PGD Progress:  30%|███       | 30/100 [00:02<00:05, 12.44it/s]\u001b[A\n",
            "PGD Progress:  32%|███▏      | 32/100 [00:02<00:05, 12.23it/s]\u001b[A\n",
            "PGD Progress:  34%|███▍      | 34/100 [00:02<00:05, 12.44it/s]\u001b[A\n",
            "PGD Progress:  36%|███▌      | 36/100 [00:02<00:04, 12.93it/s]\u001b[A\n",
            "PGD Progress:  38%|███▊      | 38/100 [00:03<00:04, 13.06it/s]\u001b[A\n",
            "PGD Progress:  40%|████      | 40/100 [00:03<00:04, 12.71it/s]\u001b[A\n",
            "PGD Progress:  42%|████▏     | 42/100 [00:03<00:04, 12.80it/s]\u001b[A\n",
            "PGD Progress:  44%|████▍     | 44/100 [00:03<00:04, 12.54it/s]\u001b[A\n",
            "PGD Progress:  46%|████▌     | 46/100 [00:03<00:04, 12.64it/s]\u001b[A\n",
            "PGD Progress:  48%|████▊     | 48/100 [00:03<00:04, 12.95it/s]\u001b[A\n",
            "PGD Progress:  50%|█████     | 50/100 [00:04<00:03, 13.08it/s]\u001b[A\n",
            "PGD Progress:  52%|█████▏    | 52/100 [00:04<00:03, 13.27it/s]\u001b[A\n",
            "PGD Progress:  54%|█████▍    | 54/100 [00:04<00:03, 13.48it/s]\u001b[A\n",
            "PGD Progress:  56%|█████▌    | 56/100 [00:04<00:03, 13.13it/s]\u001b[A\n",
            "PGD Progress:  58%|█████▊    | 58/100 [00:04<00:03, 13.21it/s]\u001b[A\n",
            "PGD Progress:  60%|██████    | 60/100 [00:04<00:03, 13.31it/s]\u001b[A\n",
            "PGD Progress:  62%|██████▏   | 62/100 [00:04<00:02, 13.16it/s]\u001b[A\n",
            "PGD Progress:  64%|██████▍   | 64/100 [00:05<00:02, 13.00it/s]\u001b[A\n",
            "PGD Progress:  66%|██████▌   | 66/100 [00:05<00:02, 13.06it/s]\u001b[A\n",
            "PGD Progress:  68%|██████▊   | 68/100 [00:05<00:02, 13.23it/s]\u001b[A\n",
            "PGD Progress:  70%|███████   | 70/100 [00:05<00:02, 13.37it/s]\u001b[A\n",
            "PGD Progress:  72%|███████▏  | 72/100 [00:05<00:02, 13.47it/s]\u001b[A\n",
            "PGD Progress:  74%|███████▍  | 74/100 [00:05<00:01, 13.55it/s]\u001b[A\n",
            "PGD Progress:  76%|███████▌  | 76/100 [00:05<00:01, 13.75it/s]\u001b[A\n",
            "PGD Progress:  78%|███████▊  | 78/100 [00:06<00:01, 13.64it/s]\u001b[A\n",
            "PGD Progress:  80%|████████  | 80/100 [00:06<00:01, 13.64it/s]\u001b[A\n",
            "PGD Progress:  82%|████████▏ | 82/100 [00:06<00:01, 13.21it/s]\u001b[A\n",
            "PGD Progress:  84%|████████▍ | 84/100 [00:06<00:01, 13.04it/s]\u001b[A\n",
            "PGD Progress:  86%|████████▌ | 86/100 [00:06<00:01, 12.75it/s]\u001b[A\n",
            "PGD Progress:  88%|████████▊ | 88/100 [00:06<00:00, 14.09it/s]\u001b[A\n",
            "PGD Progress:  90%|█████████ | 90/100 [00:06<00:00, 15.15it/s]\u001b[A\n",
            "PGD Progress:  92%|█████████▏| 92/100 [00:07<00:00, 15.73it/s]\u001b[A\n",
            "PGD Progress:  94%|█████████▍| 94/100 [00:07<00:00, 16.21it/s]\u001b[A\n",
            "PGD Progress:  96%|█████████▌| 96/100 [00:07<00:00, 16.54it/s]\u001b[A\n",
            "PGD Progress:  98%|█████████▊| 98/100 [00:07<00:00, 16.66it/s]\u001b[A\n",
            "PGD Progress: 100%|██████████| 100/100 [00:07<00:00, 13.21it/s]\n",
            "Validating...: 100%|██████████| 2/2 [00:19<00:00,  9.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error: 85.00%\n",
            "Top-5 error: 18.00%\n",
            "Accuracy: 0.15\n",
            "Top-5 Accuracy: 0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs(model, dataset_loader, img_func=fast_gradient_sign_method):\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    for imgs, labels in tqdm.tqdm(dataset_loader, desc=\"saving...\"):\n",
        "        imgs = imgs.to('cuda:0')\n",
        "        labels_gpu = labels.to('cuda:0')\n",
        "\n",
        "        # Apply the adversarial attack\n",
        "        imgs = imgs + img_func(model, imgs, labels_gpu)\n",
        "\n",
        "        # Iterate over the actual number of images in this batch\n",
        "        for i in range(imgs.size(0)):\n",
        "            X_train.append(imgs[i].detach().cpu())\n",
        "            Y_train.append(labels[i].cpu())  # No need to detach as labels are not part of the computation graph\n",
        "\n",
        "    # Combine the images and labels into a single dataset\n",
        "    sampled_test_data = [(X, Y) for X, Y in zip(X_train, Y_train)]\n",
        "\n",
        "    # Save the dataset as a pickle file\n",
        "    with open(\"fgsm.pkl\", \"wb\") as f:\n",
        "        pickle.dump(sampled_test_data, f)"
      ],
      "metadata": {
        "id": "hYcB3GDmxuKc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_imgs(model, testloader, fast_gradient_sign_method)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BigcvfhLav9c",
        "outputId": "10a4e8be-58fb-4989-d7a5-e94bf1fc98e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "saving...: 100%|██████████| 2/2 [00:00<00:00, 11.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs_pgd(model, dataset_loader, img_func=fast_gradient_sign_method):\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    for imgs, labels in tqdm.tqdm(dataset_loader, desc=\"saving...\"):\n",
        "        imgs = imgs.to('cuda:0')\n",
        "        labels_gpu = labels.to('cuda:0')\n",
        "\n",
        "        # Apply the adversarial attack\n",
        "        imgs = imgs + img_func(model, imgs, labels_gpu)\n",
        "\n",
        "        # Iterate over the actual number of images in this batch\n",
        "        for i in range(imgs.size(0)):\n",
        "            X_train.append(imgs[i].detach().cpu())\n",
        "            Y_train.append(labels[i].cpu())  # No need to detach as labels are not part of the computation graph\n",
        "\n",
        "    # Combine the images and labels into a single dataset\n",
        "    sampled_test_data = [(X, Y) for X, Y in zip(X_train, Y_train)]\n",
        "\n",
        "    # Save the dataset as a pickle file\n",
        "    with open(\"pgd.pkl\", \"wb\") as f:\n",
        "        pickle.dump(sampled_test_data, f)"
      ],
      "metadata": {
        "id": "B5Rh2BZvcd6Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_imgs_pgd(model, testloader, pgd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpdVmNbfcz9I",
        "outputId": "5a71aff6-f350-4ff1-e93c-a129b572d52b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "saving...:   0%|          | 0/2 [00:00<?, ?it/s]\n",
            "PGD Progress:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "PGD Progress:   2%|▏         | 2/100 [00:00<00:07, 12.90it/s]\u001b[A\n",
            "PGD Progress:   4%|▍         | 4/100 [00:00<00:06, 13.99it/s]\u001b[A\n",
            "PGD Progress:   6%|▌         | 6/100 [00:00<00:06, 13.65it/s]\u001b[A\n",
            "PGD Progress:   8%|▊         | 8/100 [00:00<00:06, 13.48it/s]\u001b[A\n",
            "PGD Progress:  10%|█         | 10/100 [00:00<00:06, 13.37it/s]\u001b[A\n",
            "PGD Progress:  12%|█▏        | 12/100 [00:00<00:06, 13.26it/s]\u001b[A\n",
            "PGD Progress:  14%|█▍        | 14/100 [00:01<00:06, 13.13it/s]\u001b[A\n",
            "PGD Progress:  16%|█▌        | 16/100 [00:01<00:06, 13.16it/s]\u001b[A\n",
            "PGD Progress:  18%|█▊        | 18/100 [00:01<00:06, 13.15it/s]\u001b[A\n",
            "PGD Progress:  20%|██        | 20/100 [00:01<00:06, 13.17it/s]\u001b[A\n",
            "PGD Progress:  22%|██▏       | 22/100 [00:01<00:05, 13.12it/s]\u001b[A\n",
            "PGD Progress:  24%|██▍       | 24/100 [00:01<00:05, 13.15it/s]\u001b[A\n",
            "PGD Progress:  26%|██▌       | 26/100 [00:01<00:05, 13.12it/s]\u001b[A\n",
            "PGD Progress:  28%|██▊       | 28/100 [00:02<00:05, 13.10it/s]\u001b[A\n",
            "PGD Progress:  30%|███       | 30/100 [00:02<00:05, 13.09it/s]\u001b[A\n",
            "PGD Progress:  32%|███▏      | 32/100 [00:02<00:05, 13.11it/s]\u001b[A\n",
            "PGD Progress:  34%|███▍      | 34/100 [00:02<00:05, 13.12it/s]\u001b[A\n",
            "PGD Progress:  36%|███▌      | 36/100 [00:02<00:04, 13.13it/s]\u001b[A\n",
            "PGD Progress:  38%|███▊      | 38/100 [00:02<00:04, 13.17it/s]\u001b[A\n",
            "PGD Progress:  40%|████      | 40/100 [00:03<00:04, 13.14it/s]\u001b[A\n",
            "PGD Progress:  42%|████▏     | 42/100 [00:03<00:04, 13.08it/s]\u001b[A\n",
            "PGD Progress:  44%|████▍     | 44/100 [00:03<00:04, 13.12it/s]\u001b[A\n",
            "PGD Progress:  46%|████▌     | 46/100 [00:03<00:04, 13.07it/s]\u001b[A\n",
            "PGD Progress:  48%|████▊     | 48/100 [00:03<00:03, 13.03it/s]\u001b[A\n",
            "PGD Progress:  50%|█████     | 50/100 [00:03<00:03, 13.04it/s]\u001b[A\n",
            "PGD Progress:  52%|█████▏    | 52/100 [00:03<00:03, 13.17it/s]\u001b[A\n",
            "PGD Progress:  54%|█████▍    | 54/100 [00:04<00:03, 13.12it/s]\u001b[A\n",
            "PGD Progress:  56%|█████▌    | 56/100 [00:04<00:03, 13.10it/s]\u001b[A\n",
            "PGD Progress:  58%|█████▊    | 58/100 [00:04<00:03, 13.09it/s]\u001b[A\n",
            "PGD Progress:  60%|██████    | 60/100 [00:04<00:03, 13.08it/s]\u001b[A\n",
            "PGD Progress:  62%|██████▏   | 62/100 [00:04<00:02, 13.10it/s]\u001b[A\n",
            "PGD Progress:  64%|██████▍   | 64/100 [00:04<00:02, 13.12it/s]\u001b[A\n",
            "PGD Progress:  66%|██████▌   | 66/100 [00:05<00:02, 13.07it/s]\u001b[A\n",
            "PGD Progress:  68%|██████▊   | 68/100 [00:05<00:02, 13.01it/s]\u001b[A\n",
            "PGD Progress:  70%|███████   | 70/100 [00:05<00:02, 13.03it/s]\u001b[A\n",
            "PGD Progress:  72%|███████▏  | 72/100 [00:05<00:02, 13.06it/s]\u001b[A\n",
            "PGD Progress:  74%|███████▍  | 74/100 [00:05<00:01, 13.10it/s]\u001b[A\n",
            "PGD Progress:  76%|███████▌  | 76/100 [00:05<00:01, 13.11it/s]\u001b[A\n",
            "PGD Progress:  78%|███████▊  | 78/100 [00:05<00:01, 13.12it/s]\u001b[A\n",
            "PGD Progress:  80%|████████  | 80/100 [00:06<00:01, 13.09it/s]\u001b[A\n",
            "PGD Progress:  82%|████████▏ | 82/100 [00:06<00:01, 13.16it/s]\u001b[A\n",
            "PGD Progress:  84%|████████▍ | 84/100 [00:06<00:01, 13.06it/s]\u001b[A\n",
            "PGD Progress:  86%|████████▌ | 86/100 [00:06<00:01, 13.03it/s]\u001b[A\n",
            "PGD Progress:  88%|████████▊ | 88/100 [00:06<00:00, 13.01it/s]\u001b[A\n",
            "PGD Progress:  90%|█████████ | 90/100 [00:06<00:00, 12.98it/s]\u001b[A\n",
            "PGD Progress:  92%|█████████▏| 92/100 [00:07<00:00, 13.06it/s]\u001b[A\n",
            "PGD Progress:  94%|█████████▍| 94/100 [00:07<00:00, 13.06it/s]\u001b[A\n",
            "PGD Progress:  96%|█████████▌| 96/100 [00:07<00:00, 13.04it/s]\u001b[A\n",
            "PGD Progress:  98%|█████████▊| 98/100 [00:07<00:00, 13.09it/s]\u001b[A\n",
            "PGD Progress: 100%|██████████| 100/100 [00:07<00:00, 13.11it/s]\n",
            "saving...:  50%|█████     | 1/2 [00:07<00:07,  7.66s/it]\n",
            "PGD Progress:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "PGD Progress:   2%|▏         | 2/100 [00:00<00:05, 18.81it/s]\u001b[A\n",
            "PGD Progress:   4%|▍         | 4/100 [00:00<00:05, 18.52it/s]\u001b[A\n",
            "PGD Progress:   6%|▌         | 6/100 [00:00<00:05, 17.54it/s]\u001b[A\n",
            "PGD Progress:   8%|▊         | 8/100 [00:00<00:05, 17.73it/s]\u001b[A\n",
            "PGD Progress:  10%|█         | 10/100 [00:00<00:05, 17.52it/s]\u001b[A\n",
            "PGD Progress:  12%|█▏        | 12/100 [00:00<00:05, 17.44it/s]\u001b[A\n",
            "PGD Progress:  14%|█▍        | 14/100 [00:00<00:04, 17.38it/s]\u001b[A\n",
            "PGD Progress:  16%|█▌        | 16/100 [00:00<00:04, 17.26it/s]\u001b[A\n",
            "PGD Progress:  18%|█▊        | 18/100 [00:01<00:04, 17.16it/s]\u001b[A\n",
            "PGD Progress:  20%|██        | 20/100 [00:01<00:04, 17.18it/s]\u001b[A\n",
            "PGD Progress:  22%|██▏       | 22/100 [00:01<00:04, 15.96it/s]\u001b[A\n",
            "PGD Progress:  24%|██▍       | 24/100 [00:01<00:05, 14.59it/s]\u001b[A\n",
            "PGD Progress:  26%|██▌       | 26/100 [00:01<00:05, 14.16it/s]\u001b[A\n",
            "PGD Progress:  28%|██▊       | 28/100 [00:01<00:05, 14.18it/s]\u001b[A\n",
            "PGD Progress:  30%|███       | 30/100 [00:01<00:05, 13.60it/s]\u001b[A\n",
            "PGD Progress:  32%|███▏      | 32/100 [00:02<00:04, 13.79it/s]\u001b[A\n",
            "PGD Progress:  34%|███▍      | 34/100 [00:02<00:04, 13.96it/s]\u001b[A\n",
            "PGD Progress:  36%|███▌      | 36/100 [00:02<00:04, 13.81it/s]\u001b[A\n",
            "PGD Progress:  38%|███▊      | 38/100 [00:02<00:04, 13.56it/s]\u001b[A\n",
            "PGD Progress:  40%|████      | 40/100 [00:02<00:04, 13.70it/s]\u001b[A\n",
            "PGD Progress:  42%|████▏     | 42/100 [00:02<00:04, 13.64it/s]\u001b[A\n",
            "PGD Progress:  44%|████▍     | 44/100 [00:02<00:04, 13.69it/s]\u001b[A\n",
            "PGD Progress:  46%|████▌     | 46/100 [00:03<00:03, 13.95it/s]\u001b[A\n",
            "PGD Progress:  48%|████▊     | 48/100 [00:03<00:03, 14.02it/s]\u001b[A\n",
            "PGD Progress:  50%|█████     | 50/100 [00:03<00:03, 13.54it/s]\u001b[A\n",
            "PGD Progress:  52%|█████▏    | 52/100 [00:03<00:03, 13.27it/s]\u001b[A\n",
            "PGD Progress:  54%|█████▍    | 54/100 [00:03<00:03, 13.43it/s]\u001b[A\n",
            "PGD Progress:  56%|█████▌    | 56/100 [00:03<00:03, 13.53it/s]\u001b[A\n",
            "PGD Progress:  58%|█████▊    | 58/100 [00:03<00:03, 13.69it/s]\u001b[A\n",
            "PGD Progress:  60%|██████    | 60/100 [00:04<00:02, 13.70it/s]\u001b[A\n",
            "PGD Progress:  62%|██████▏   | 62/100 [00:04<00:02, 13.86it/s]\u001b[A\n",
            "PGD Progress:  64%|██████▍   | 64/100 [00:04<00:02, 13.81it/s]\u001b[A\n",
            "PGD Progress:  66%|██████▌   | 66/100 [00:04<00:02, 13.64it/s]\u001b[A\n",
            "PGD Progress:  68%|██████▊   | 68/100 [00:04<00:02, 13.72it/s]\u001b[A\n",
            "PGD Progress:  70%|███████   | 70/100 [00:04<00:02, 13.99it/s]\u001b[A\n",
            "PGD Progress:  72%|███████▏  | 72/100 [00:04<00:01, 14.10it/s]\u001b[A\n",
            "PGD Progress:  74%|███████▍  | 74/100 [00:05<00:01, 13.98it/s]\u001b[A\n",
            "PGD Progress:  76%|███████▌  | 76/100 [00:05<00:01, 13.70it/s]\u001b[A\n",
            "PGD Progress:  78%|███████▊  | 78/100 [00:05<00:01, 13.52it/s]\u001b[A\n",
            "PGD Progress:  80%|████████  | 80/100 [00:05<00:01, 13.49it/s]\u001b[A\n",
            "PGD Progress:  82%|████████▏ | 82/100 [00:05<00:01, 13.69it/s]\u001b[A\n",
            "PGD Progress:  84%|████████▍ | 84/100 [00:05<00:01, 13.77it/s]\u001b[A\n",
            "PGD Progress:  86%|████████▌ | 86/100 [00:05<00:00, 14.04it/s]\u001b[A\n",
            "PGD Progress:  88%|████████▊ | 88/100 [00:06<00:00, 14.03it/s]\u001b[A\n",
            "PGD Progress:  90%|█████████ | 90/100 [00:06<00:00, 13.90it/s]\u001b[A\n",
            "PGD Progress:  92%|█████████▏| 92/100 [00:06<00:00, 13.64it/s]\u001b[A\n",
            "PGD Progress:  94%|█████████▍| 94/100 [00:06<00:00, 13.31it/s]\u001b[A\n",
            "PGD Progress:  96%|█████████▌| 96/100 [00:06<00:00, 13.19it/s]\u001b[A\n",
            "PGD Progress:  98%|█████████▊| 98/100 [00:06<00:00, 13.10it/s]\u001b[A\n",
            "PGD Progress: 100%|██████████| 100/100 [00:07<00:00, 14.28it/s]\n",
            "saving...: 100%|██████████| 2/2 [00:14<00:00,  7.35s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def self_check(model, result_set='fgsm.pkl'):\n",
        "    # Load the adversarial and original test set\n",
        "    with open(result_set, \"rb\") as f:\n",
        "        resultset = pickle.load(f)\n",
        "    with open(\"/content/drive/MyDrive/test_set.pkl\", \"rb\") as f2:\n",
        "        testset = pickle.load(f2)\n",
        "\n",
        "    # Prepare the evaluation set\n",
        "    eval_set = []\n",
        "    for org, adv in zip(testset, resultset):\n",
        "        assert org[1] == adv[1]  # Make sure labels match\n",
        "        eval_set.append((org[0], adv[0], org[1]))  # Tuple of (original image, adversarial image, label)\n",
        "\n",
        "    # Prepare DataLoader for evaluation\n",
        "    testloader = torch.utils.data.DataLoader(eval_set, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Initialize counters\n",
        "    org_tp, org_tp_5, adv_tp, adv_tp_5, counter, diff = 0., 0., 0., 0., 0., 0.\n",
        "\n",
        "    # Evaluate the model\n",
        "    for imgs, adv_imgs, labels in tqdm.tqdm(testloader, desc=\"Validating...\"):\n",
        "        imgs = imgs.to('cuda:0')\n",
        "        adv_imgs = adv_imgs.to('cuda:0')\n",
        "        labels = labels.to('cuda:0')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            org_preds = model(imgs)\n",
        "            adv_preds = model(adv_imgs)\n",
        "\n",
        "        # Calculate the differences\n",
        "        diff += torch.sum(torch.abs(adv_imgs - imgs)) / (3 * 32 * 32)  # Normalize by the number of elements per image\n",
        "\n",
        "        # Calculate accuracies\n",
        "        org_tp += (org_preds.argmax(dim=-1) == labels).sum()\n",
        "        org_tp_5 += (org_preds.topk(5, dim=-1)[1] == labels[..., None]).any(dim=-1).sum()\n",
        "        adv_tp += (adv_preds.argmax(dim=-1) == labels).sum()\n",
        "        adv_tp_5 += (adv_preds.topk(5, dim=-1)[1] == labels[..., None]).any(dim=-1).sum()\n",
        "        counter += org_preds.shape[0]\n",
        "\n",
        "    # Calculate final accuracies\n",
        "    org_acc = org_tp.float().item() / counter\n",
        "    org_top5 = org_tp_5.float().item() / counter\n",
        "    adv_acc = adv_tp.float().item() / counter\n",
        "    adv_top5 = adv_tp_5.float().item() / counter\n",
        "\n",
        "    # Determine if the results are satisfactory\n",
        "    result = \"correct\" if org_acc - adv_acc >= 0.2 and org_top5 - adv_top5 >= 0.15 else \"need to improve\" # and diff / counter <= 0.1\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Top-1 error on original samples: {(100.0 * (1 - org_acc)):4.2f}%; \\n Top-1 error on adversarial samples: {(100.0 * (1 - adv_acc)):4.2f}%\")\n",
        "    print(f\"Top-5 error on original samples: {(100.0 * (1 - org_top5)):4.2f}%; \\n Top-5 error on adversarial samples: {(100.0 * (1 - adv_top5)):4.2f}%\")\n",
        "    print(f'org_acc - adv_acc: {(100.0 * (org_acc - adv_acc)):4.2f}% \\n org_top5 - adv_top5: {(100.0 * (org_top5 - adv_top5)):4.2f}%')\n",
        "    print(f'diff / counter: {(diff / counter)}')\n",
        "    print(result)\n",
        "\n",
        "    # Warn if the average perturbation per image is too large\n",
        "    if (diff / counter > 0.1):\n",
        "        print(\"epsilon > 0.1\")"
      ],
      "metadata": {
        "id": "E7FDU-nquAmH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the model is loaded and set to evaluation mode\n",
        "self_check(model, 'fgsm.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq6v4f8fuJ8e",
        "outputId": "b7f57aed-f92a-40a5-ae2e-5a6301f2db2d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 25/25 [00:01<00:00, 22.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error on original samples: 18.00%; \n",
            " Top-1 error on adversarial samples: 80.00%\n",
            "Top-5 error on original samples: 3.00%; \n",
            " Top-5 error on adversarial samples: 18.00%\n",
            "org_acc - adv_acc: 62.00% \n",
            " org_top5 - adv_top5: 15.00%\n",
            "diff / counter: 0.19260919094085693\n",
            "correct\n",
            "epsilon > 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the model is loaded and set to evaluation mode\n",
        "self_check(model, 'pgd.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYRhP5sSuOdh",
        "outputId": "1866de1e-5f07-428c-ee89-3d36bd46aa24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating...: 100%|██████████| 25/25 [00:01<00:00, 22.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 error on original samples: 18.00%; \n",
            " Top-1 error on adversarial samples: 85.00%\n",
            "Top-5 error on original samples: 3.00%; \n",
            " Top-5 error on adversarial samples: 18.00%\n",
            "org_acc - adv_acc: 67.00% \n",
            " org_top5 - adv_top5: 15.00%\n",
            "diff / counter: 0.4278186559677124\n",
            "correct\n",
            "epsilon > 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References:\n",
        "1. [Adversarial attacks with FGSM (Fast Gradient Sign Method)](https://pyimagesearch.com/2021/03/01/adversarial-attacks-with-fgsm-fast-gradient-sign-method/)\n",
        "2. [Adversarial example using FGSM](https://www.tensorflow.org/tutorials/generative/adversarial_fgsm)\n",
        "3. [Adversarial Training for Free!](https://proceedings.neurips.cc/paper_files/paper/2019/file/7503cfacd12053d309b6bed5c89de212-Paper.pdf)\n",
        "4. [Towards Deep Learning Models Resistant to Adversarial\n",
        "Attacks](https://arxiv.org/pdf/1706.06083.pdf)"
      ],
      "metadata": {
        "id": "3mqP_p74E1pd"
      }
    }
  ]
}